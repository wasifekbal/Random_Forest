{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>763</td>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>764</td>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>765</td>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>766</td>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>767</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148             72             35        0  33.6   \n",
       "1              1       85             66             29        0  26.6   \n",
       "2              8      183             64              0        0  23.3   \n",
       "3              1       89             66             23       94  28.1   \n",
       "4              0      137             40             35      168  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763           10      101             76             48      180  32.9   \n",
       "764            2      122             70             27        0  36.8   \n",
       "765            5      121             72             23      112  26.2   \n",
       "766            1      126             60              0        0  30.1   \n",
       "767            1       93             70             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                       0.627   50        1  \n",
       "1                       0.351   31        0  \n",
       "2                       0.672   32        1  \n",
       "3                       0.167   21        0  \n",
       "4                       2.288   33        1  \n",
       "..                        ...  ...      ...  \n",
       "763                     0.171   63        0  \n",
       "764                     0.340   27        0  \n",
       "765                     0.245   30        0  \n",
       "766                     0.349   47        1  \n",
       "767                     0.315   23        0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,:-1]\n",
    "Y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, let's try with nomal DecisionTreeClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = dtc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7662337662337663"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_test,Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class RandomForest ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest():\n",
    "    def __init__(my,n_estimators=100,\n",
    "                 criterion='gini',\n",
    "                 max_depth=None,\n",
    "                 splitter='best',\n",
    "                 max_samples=None,\n",
    "                 max_features=None,):\n",
    "        \"\"\"\n",
    "        n_estimators : int, default=100, \n",
    "            The number of trees in the forest.\n",
    "        \n",
    "        criterion : {\"gini\", \"entropy\"}, default=\"gini\"\n",
    "            The function to measure the quality of a split. Supported criteria are\n",
    "            \"gini\" for the Gini impurity and \"entropy\" for the information gain.\n",
    "            Note: this parameter is tree-specific.\n",
    "        \n",
    "        max_depth : int, default=None\n",
    "            The maximum depth of the tree. If None, then nodes are expanded until\n",
    "            all leaves are pure.\n",
    "        \n",
    "        splitter : {\"best\", \"random\"}, default=\"best\"\n",
    "            The strategy used to choose the split at each node. Supported\n",
    "            strategies are \"best\" to choose the best split and \"random\" to choose\n",
    "            the best random split.\n",
    "        \n",
    "        max_samples : int or float, default=None\n",
    "\n",
    "            - If None (default), then draw `X.shape[0]` samples.\n",
    "            - If int, then draw `max_samples` samples.\n",
    "            - If float, then draw `max_samples * X.shape[0]` samples. Thus,\n",
    "              `max_samples` should be in the interval `(0, 1)`.\n",
    "              \n",
    "        max_features : int, float or {\"auto\", \"sqrt\", \"log2\"}, default=None\n",
    "            The number of features to consider when looking for the best split:\n",
    "\n",
    "            - If int, then consider `max_features` features at each split.\n",
    "            - If float, then `max_features` is a fraction and\n",
    "              `int(max_features * n_features)` features are considered at each\n",
    "              split.\n",
    "            - If \"auto\", then `max_features=sqrt(n_features)`.\n",
    "            - If \"sqrt\", then `max_features=sqrt(n_features)`.\n",
    "            - If \"log2\", then `max_features=log2(n_features)`.\n",
    "            - If None, then `max_features=n_features`.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        my.n_estimators = n_estimators\n",
    "        my.criterion = criterion\n",
    "        my.max_depth = max_depth\n",
    "        my.splitter = splitter\n",
    "        my.max_features = max_features\n",
    "        \n",
    "        if max_samples==None:\n",
    "            my.max_samples = None\n",
    "            \n",
    "        elif type(max_samples) == int:\n",
    "            my.max_samples = max_samples\n",
    "            \n",
    "        elif type(max_samples) == float:\n",
    "            if max_samples < 0:\n",
    "                my.max_samples = 0\n",
    "            elif max_samples > 1:\n",
    "                my.max_samples = 1\n",
    "            else:\n",
    "                my.max_samples = max_samples\n",
    "        else:\n",
    "            raise TypeError('Max_sample must be None, int, or float')\n",
    "        \n",
    "        # initializing DTCs ...\n",
    "        \n",
    "        my.DTCs = list(DecisionTreeClassifier(criterion=my.criterion,\n",
    "                                              splitter=my.splitter,\n",
    "                                              max_depth=my.max_depth,\n",
    "                                              max_features=my.max_features) for _ in range(my.n_estimators))\n",
    "        \n",
    "    \n",
    "    def ndarray_check(my,arr):\n",
    "        \n",
    "        if type(arr) == np.ndarray:\n",
    "            return arr\n",
    "        elif (type(arr)==pd.core.frame.DataFrame) | (type(arr)==pd.core.series.Series):\n",
    "            return arr.values\n",
    "    \n",
    "    def random_indices(my,data):\n",
    "        if my.max_samples == None:\n",
    "            return np.array(range(0,data.shape[0]))        \n",
    "        elif type(my.max_samples) == int:\n",
    "            return np.random.randint(low=0,high=data.shape[0],size=max_samples)\n",
    "        else:            \n",
    "            size=int(df.shape[0]*my.max_samples)\n",
    "\n",
    "            return np.random.randint(low=0,high=data.shape[0],size=size)\n",
    "        \n",
    "    def decide(my,arr):\n",
    "        final = []\n",
    "        arr = arr.T\n",
    "        for i in arr:\n",
    "            v,c = np.unique(i,return_counts=True)\n",
    "            final.append(v[np.argmax(c)])\n",
    "        return np.array(final)\n",
    "    \n",
    "    def fit(my,X,Y):\n",
    "        \n",
    "        X = my.ndarray_check(X)\n",
    "        Y = my.ndarray_check(Y)\n",
    "        for i in my.DTCs:            \n",
    "            indices = my.random_indices(X)\n",
    "            samplesX = X[indices]\n",
    "            samplesY = Y[indices]            \n",
    "            i.fit(samplesX,samplesY)\n",
    "        \n",
    "        return my\n",
    "    \n",
    "    def predict(my,X):\n",
    "        \n",
    "        X = my.ndarray_check(X)        \n",
    "        Y_pred = []        \n",
    "        for i in my.DTCs:\n",
    "            Y_pred.append(i.predict(X))        \n",
    "        Y_pred = my.decide(np.array(Y_pred))\n",
    "        \n",
    "        return np.array(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = RandomForest(max_samples=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.RandomForest at 0x1f85170e6c8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = test.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8051948051948052"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, let's try with actual RandomForestClassifier from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(max_samples=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_samples=0.7)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7792207792207793"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_test,y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
